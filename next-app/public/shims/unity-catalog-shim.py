# Unity Catalog Shim - Complete bundled version
# Auto-generated by scripts/bundle-unity-catalog.js
# Requires pyspark-shim.py to be loaded first

import pandas as pd
import re
from datetime import datetime

# ============ CATALOG MODULE ============


# ============ GLOBAL METADATA REGISTRY ============

# Catalog registry: catalog_name -> catalog metadata
_CATALOG_REGISTRY = {}

# Table data storage: 'catalog.schema.table' -> DataFrame
_TABLE_REGISTRY = {}

# Temp views (session-scoped): view_name -> {'df': DataFrame, 'definition': str}
_TEMP_VIEWS = {}

# ACL registry: 'catalog.schema.table' -> [grant records]
_ACL_REGISTRY = {}

# Current context
_CURRENT_CATALOG = 'spark_catalog'
_CURRENT_SCHEMA = 'default'


# ============ INITIALIZATION ============

def _initialize_default_catalog():
    """Set up spark_catalog with default schema"""
    global _CATALOG_REGISTRY
    _CATALOG_REGISTRY['spark_catalog'] = {
        'name': 'spark_catalog',
        'comment': 'Default Spark catalog',
        'properties': {},
        'created_at': datetime.now().isoformat(),
        'owner': 'spark',
        'schemas': {
            'default': {
                'name': 'default',
                'comment': 'Default schema',
                'created_at': datetime.now().isoformat(),
                'owner': 'spark',
                'tables': {}
            }
        }
    }


# Initialize on module load
_initialize_default_catalog()


# ============ CONTEXT FUNCTIONS ============

def current_catalog():
    """Return current catalog name"""
    return _CURRENT_CATALOG


def current_database():
    """Return current schema/database name"""
    return _CURRENT_SCHEMA


def set_current_catalog(catalog_name: str):
    """Set current catalog context"""
    global _CURRENT_CATALOG
    if catalog_name not in _CATALOG_REGISTRY:
        raise ValueError(f"Catalog '{catalog_name}' does not exist")
    _CURRENT_CATALOG = catalog_name


def set_current_schema(schema_name: str):
    """Set current schema context (can be catalog.schema or just schema)"""
    global _CURRENT_CATALOG, _CURRENT_SCHEMA

    if '.' in schema_name:
        # Format: catalog.schema
        parts = schema_name.split('.')
        catalog, schema = parts[0], parts[1]
        if catalog not in _CATALOG_REGISTRY:
            raise ValueError(f"Catalog '{catalog}' does not exist")
        if schema not in _CATALOG_REGISTRY[catalog]['schemas']:
            raise ValueError(f"Schema '{schema}' does not exist in catalog '{catalog}'")
        _CURRENT_CATALOG = catalog
        _CURRENT_SCHEMA = schema
    else:
        # Format: schema (use current catalog)
        if schema_name not in _CATALOG_REGISTRY[_CURRENT_CATALOG]['schemas']:
            raise ValueError(f"Schema '{schema_name}' does not exist in catalog '{_CURRENT_CATALOG}'")
        _CURRENT_SCHEMA = schema_name


# ============ CATALOG MANAGER ============

class CatalogManager:
    """Manages Unity Catalog metadata and operations"""

    @staticmethod
    def create_catalog(name: str, comment: str = None, properties: dict = None, if_not_exists: bool = False):
        """Create a new catalog"""
        global _CATALOG_REGISTRY

        if name in _CATALOG_REGISTRY:
            if if_not_exists:
                return  # Silently succeed
            raise ValueError(f"Catalog '{name}' already exists")

        _CATALOG_REGISTRY[name] = {
            'name': name,
            'comment': comment,
            'properties': properties or {},
            'created_at': datetime.now().isoformat(),
            'owner': 'user',
            'schemas': {}
        }

    @staticmethod
    def create_schema(full_path: str, comment: str = None, if_not_exists: bool = False):
        """
        Create schema within catalog.
        full_path can be 'catalog.schema' or just 'schema' (uses current catalog)
        """
        global _CATALOG_REGISTRY

        if '.' in full_path:
            catalog, schema = full_path.split('.', 1)
        else:
            catalog, schema = _CURRENT_CATALOG, full_path

        if catalog not in _CATALOG_REGISTRY:
            raise ValueError(f"Catalog '{catalog}' does not exist")

        if schema in _CATALOG_REGISTRY[catalog]['schemas']:
            if if_not_exists:
                return  # Silently succeed
            raise ValueError(f"Schema '{schema}' already exists in catalog '{catalog}'")

        _CATALOG_REGISTRY[catalog]['schemas'][schema] = {
            'name': schema,
            'comment': comment,
            'created_at': datetime.now().isoformat(),
            'owner': 'user',
            'tables': {}
        }

    @staticmethod
    def register_table(name: str, df, is_managed: bool = True, location: str = None,
                      table_type: str = 'MANAGED', comment: str = None, properties: dict = None):
        """
        Register table with metadata.
        name can be 'table', 'schema.table', or 'catalog.schema.table'
        """
        global _TABLE_REGISTRY, _CATALOG_REGISTRY

        catalog, schema, table = CatalogManager.resolve_name(name)
        qualified_name = CatalogManager.qualified_name(catalog, schema, table)

        # Ensure catalog and schema exist
        if catalog not in _CATALOG_REGISTRY:
            raise ValueError(f"Catalog '{catalog}' does not exist")
        if schema not in _CATALOG_REGISTRY[catalog]['schemas']:
            raise ValueError(f"Schema '{schema}' does not exist in catalog '{catalog}'")

        # Infer column metadata from DataFrame
        columns = CatalogManager._infer_columns(df)

        # Store table metadata
        _CATALOG_REGISTRY[catalog]['schemas'][schema]['tables'][table] = {
            'name': table,
            'type': table_type,  # MANAGED, EXTERNAL, VIEW
            'columns': columns,
            'location': location,
            'properties': properties or {},
            'comment': comment,
            'view_text': None,
            'created_at': datetime.now().isoformat()
        }

        # Store actual DataFrame
        _TABLE_REGISTRY[qualified_name] = df

    @staticmethod
    def _infer_columns(df):
        """Extract column metadata from DataFrame"""
        columns = []
        pdf = df._pdf if hasattr(df, '_pdf') else df
        for i, (col_name, dtype) in enumerate(pdf.dtypes.items()):
            columns.append({
                'name': col_name,
                'type': CatalogManager._pandas_to_spark_type(dtype),
                'ordinal': i,
                'comment': None
            })
        return columns

    @staticmethod
    def _pandas_to_spark_type(dtype) -> str:
        """Map pandas dtypes to Spark SQL types"""
        dtype_str = str(dtype)
        mapping = {
            'int64': 'BIGINT',
            'int32': 'INT',
            'int16': 'SMALLINT',
            'int8': 'TINYINT',
            'float64': 'DOUBLE',
            'float32': 'FLOAT',
            'object': 'STRING',
            'bool': 'BOOLEAN',
            'datetime64[ns]': 'TIMESTAMP',
            'category': 'STRING'
        }
        return mapping.get(dtype_str, 'STRING')

    @staticmethod
    def resolve_name(name: str) -> tuple:
        """
        Resolve table name to (catalog, schema, table).

        Examples:
        - 'mytable' -> (current_catalog, current_schema, 'mytable')
        - 'myschema.mytable' -> (current_catalog, 'myschema', 'mytable')
        - 'catalog.schema.table' -> ('catalog', 'schema', 'table')
        """
        parts = name.split('.')

        if len(parts) == 1:
            return (_CURRENT_CATALOG, _CURRENT_SCHEMA, parts[0])
        elif len(parts) == 2:
            return (_CURRENT_CATALOG, parts[0], parts[1])
        elif len(parts) == 3:
            return (parts[0], parts[1], parts[2])
        else:
            raise ValueError(f"Invalid table name: {name}")

    @staticmethod
    def qualified_name(catalog: str, schema: str, table: str) -> str:
        """Generate fully qualified name"""
        return f"{catalog}.{schema}.{table}"

    @staticmethod
    def get_table(name: str):
        """Retrieve table by name (resolves relative names)"""
        # Check temp views first
        if name in _TEMP_VIEWS:
            return _TEMP_VIEWS[name]['df']

        catalog, schema, table = CatalogManager.resolve_name(name)
        qualified_name = CatalogManager.qualified_name(catalog, schema, table)

        if qualified_name not in _TABLE_REGISTRY:
            raise ValueError(f"Table '{qualified_name}' not found")

        return _TABLE_REGISTRY[qualified_name]

    @staticmethod
    def get_table_metadata(name: str) -> dict:
        """Get table metadata"""
        catalog, schema, table = CatalogManager.resolve_name(name)

        if catalog not in _CATALOG_REGISTRY:
            raise ValueError(f"Catalog '{catalog}' does not exist")
        if schema not in _CATALOG_REGISTRY[catalog]['schemas']:
            raise ValueError(f"Schema '{schema}' does not exist")
        if table not in _CATALOG_REGISTRY[catalog]['schemas'][schema]['tables']:
            raise ValueError(f"Table '{table}' does not exist")

        return _CATALOG_REGISTRY[catalog]['schemas'][schema]['tables'][table]

    @staticmethod
    def get_catalogs() -> list:
        """Get list of catalog names"""
        return list(_CATALOG_REGISTRY.keys())

    @staticmethod
    def get_schemas(catalog: str = None) -> list:
        """Get list of schema names in catalog"""
        cat = catalog or _CURRENT_CATALOG
        if cat not in _CATALOG_REGISTRY:
            raise ValueError(f"Catalog '{cat}' does not exist")
        return list(_CATALOG_REGISTRY[cat]['schemas'].keys())

    @staticmethod
    def get_tables(schema_path: str = None) -> list:
        """Get list of table names in schema"""
        if schema_path:
            if '.' in schema_path:
                catalog, schema = schema_path.split('.')
            else:
                catalog, schema = _CURRENT_CATALOG, schema_path
        else:
            catalog, schema = _CURRENT_CATALOG, _CURRENT_SCHEMA

        if catalog not in _CATALOG_REGISTRY:
            raise ValueError(f"Catalog '{catalog}' does not exist")
        if schema not in _CATALOG_REGISTRY[catalog]['schemas']:
            raise ValueError(f"Schema '{schema}' does not exist")

        return list(_CATALOG_REGISTRY[catalog]['schemas'][schema]['tables'].keys())

    # ============ ACL METHODS ============

    @staticmethod
    def grant_privilege(object_type: str, object_name: str, privilege: str, principal: str):
        """Grant privilege on object to principal (stored but not enforced)"""
        global _ACL_REGISTRY

        if object_name not in _ACL_REGISTRY:
            _ACL_REGISTRY[object_name] = []

        # Check if grant already exists
        for grant in _ACL_REGISTRY[object_name]:
            if grant['principal'] == principal and grant['privilege'] == privilege:
                return  # Already exists

        _ACL_REGISTRY[object_name].append({
            'principal': principal,
            'privilege': privilege.upper(),
            'object_type': object_type.upper(),
            'granted_at': datetime.now().isoformat(),
            'granted_by': 'user'
        })

    @staticmethod
    def revoke_privilege(object_type: str, object_name: str, privilege: str, principal: str):
        """Revoke privilege on object from principal"""
        global _ACL_REGISTRY

        if object_name not in _ACL_REGISTRY:
            return  # Nothing to revoke

        _ACL_REGISTRY[object_name] = [
            grant for grant in _ACL_REGISTRY[object_name]
            if not (grant['principal'] == principal and grant['privilege'] == privilege.upper())
        ]

    @staticmethod
    def show_grants(object_name: str) -> list:
        """Return list of grants for object"""
        return _ACL_REGISTRY.get(object_name, [])

    # ============ TEMP VIEWS ============

    @staticmethod
    def create_temp_view(name: str, df, definition: str = None):
        """Create temporary view (session-scoped)"""
        global _TEMP_VIEWS
        _TEMP_VIEWS[name] = {
            'df': df,
            'definition': definition
        }

    @staticmethod
    def drop_temp_view(name: str):
        """Drop temporary view"""
        global _TEMP_VIEWS
        if name in _TEMP_VIEWS:
            del _TEMP_VIEWS[name]


# ============ SQL MODULE ============


def execute_sql(sql_str: str, spark_session=None):
    """
    Main SQL execution entry point.
    Routes SQL commands to appropriate handlers.

    Returns: DataFrame with results
    """
    sql = sql_str.strip()
    sql_upper = sql.upper()

    try:
        # DDL Commands
        if sql_upper.startswith('CREATE CATALOG'):
            return _handle_create_catalog(sql)
        elif sql_upper.startswith('CREATE SCHEMA') or sql_upper.startswith('CREATE DATABASE'):
            return _handle_create_schema(sql)
        elif sql_upper.startswith('CREATE TABLE'):
            return _handle_create_table(sql, spark_session)
        elif sql_upper.startswith('CREATE VIEW') or sql_upper.startswith('CREATE OR REPLACE VIEW'):
            return _handle_create_view(sql, spark_session)
        elif sql_upper.startswith('CREATE TEMP VIEW') or sql_upper.startswith('CREATE TEMPORARY VIEW') or sql_upper.startswith('CREATE OR REPLACE TEMP VIEW') or sql_upper.startswith('CREATE OR REPLACE TEMPORARY VIEW'):
            return _handle_create_temp_view(sql, spark_session)
        elif sql_upper.startswith('ALTER TABLE'):
            return _handle_alter_table(sql)

        # DQL Commands
        elif sql_upper.startswith('SHOW CATALOGS'):
            return _handle_show_catalogs()
        elif sql_upper.startswith('SHOW SCHEMAS') or sql_upper.startswith('SHOW DATABASES'):
            return _handle_show_schemas(sql)
        elif sql_upper.startswith('SHOW TABLES'):
            return _handle_show_tables(sql)
        elif sql_upper.startswith('DESCRIBE TABLE') or sql_upper.startswith('DESC TABLE'):
            return _handle_describe_table(sql)
        elif sql_upper.startswith('DESCRIBE') or sql_upper.startswith('DESC'):
            return _handle_describe_table(sql)
        elif sql_upper.startswith('SHOW GRANTS'):
            return _handle_show_grants(sql)

        # ACL Commands
        elif sql_upper.startswith('GRANT'):
            return _handle_grant(sql)
        elif sql_upper.startswith('REVOKE'):
            return _handle_revoke(sql)

        # Context Commands
        elif sql_upper.startswith('USE'):
            return _handle_use(sql)

        # SELECT from information_schema
        elif 'INFORMATION_SCHEMA' in sql_upper:
            return _handle_information_schema_query(sql, spark_session)

        # Regular SELECT - not supported (use DataFrame API)
        elif sql_upper.startswith('SELECT'):
            raise NotImplementedError(
                "Use PySpark DataFrame API for queries. "
                "spark.sql() supports only DDL/DQL/ACL commands and information_schema queries."
            )

        else:
            raise ValueError(f"Unsupported SQL command: {sql[:80]}")

    except Exception as e:
        # Return error as DataFrame for koan feedback
        from .core import DataFrame
        error_msg = f"SQL Error: {str(e)}"
        return DataFrame(pd.DataFrame({'Error': [error_msg]}))


# ============ DDL HANDLERS ============

def _handle_create_catalog(sql: str):
    """
    CREATE CATALOG [IF NOT EXISTS] catalog_name [COMMENT 'text'] [PROPERTIES (...)]
    """
    from .core import DataFrame

    # Pattern: CREATE CATALOG [IF NOT EXISTS] name
    pattern = r"CREATE\s+CATALOG\s+(IF\s+NOT\s+EXISTS\s+)?(\w+)"
    match = re.search(pattern, sql, re.IGNORECASE)

    if not match:
        raise ValueError("Invalid CREATE CATALOG syntax")

    if_not_exists = match.group(1) is not None
    catalog_name = match.group(2)

    # Extract optional comment
    comment_match = re.search(r"COMMENT\s+'([^']+)'", sql, re.IGNORECASE)
    comment = comment_match.group(1) if comment_match else None

    # Create catalog
    CatalogManager.create_catalog(catalog_name, comment=comment, if_not_exists=if_not_exists)

    return DataFrame(pd.DataFrame({'Result': [f'Catalog {catalog_name} created']}))


def _handle_create_schema(sql: str):
    """
    CREATE SCHEMA [IF NOT EXISTS] [catalog.]schema [COMMENT 'text']
    """
    from .core import DataFrame

    # Pattern: CREATE SCHEMA [IF NOT EXISTS] name
    pattern = r"CREATE\s+(SCHEMA|DATABASE)\s+(IF\s+NOT\s+EXISTS\s+)?([\w.]+)"
    match = re.search(pattern, sql, re.IGNORECASE)

    if not match:
        raise ValueError("Invalid CREATE SCHEMA syntax")

    if_not_exists = match.group(2) is not None
    schema_name = match.group(3)

    # Extract optional comment
    comment_match = re.search(r"COMMENT\s+'([^']+)'", sql, re.IGNORECASE)
    comment = comment_match.group(1) if comment_match else None

    # Create schema
    CatalogManager.create_schema(schema_name, comment=comment, if_not_exists=if_not_exists)

    return DataFrame(pd.DataFrame({'Result': [f'Schema {schema_name} created']}))


def _handle_create_table(sql: str, spark_session):
    """
    CREATE TABLE [catalog.][schema.]table (col1 type, col2 type, ...) [USING delta] [LOCATION 'path']
    """
    from .core import DataFrame

    # Pattern: CREATE TABLE name (columns) [USING format] [LOCATION 'path']
    table_pattern = r"CREATE\s+TABLE\s+([\w.]+)\s+\((.*?)\)"
    match = re.search(table_pattern, sql, re.IGNORECASE | re.DOTALL)

    if not match:
        raise ValueError("Invalid CREATE TABLE syntax")

    table_name = match.group(1)
    columns_str = match.group(2)

    # Parse columns
    column_defs = []
    for col_def in columns_str.split(','):
        col_def = col_def.strip()
        parts = col_def.split()
        if len(parts) >= 2:
            col_name = parts[0]
            col_type = parts[1]
            column_defs.append((col_name, col_type))

    # Check for USING and LOCATION
    using_match = re.search(r"USING\s+(\w+)", sql, re.IGNORECASE)
    location_match = re.search(r"LOCATION\s+'([^']+)'", sql, re.IGNORECASE)

    table_type = 'EXTERNAL' if location_match else 'MANAGED'
    location = location_match.group(1) if location_match else None

    # Create empty DataFrame with specified columns
    df_data = {col_name: [] for col_name, col_type in column_defs}
    df = DataFrame(pd.DataFrame(df_data))

    # Register table
    CatalogManager.register_table(
        table_name,
        df,
        is_managed=(table_type == 'MANAGED'),
        location=location,
        table_type=table_type
    )

    return DataFrame(pd.DataFrame({'Result': [f'Table {table_name} created']}))


def _handle_create_view(sql: str, spark_session):
    """
    CREATE [OR REPLACE] VIEW [catalog.][schema.]view AS select_statement
    """
    from .core import DataFrame

    # Not fully implemented - would need SELECT parsing
    # For koans, this is a placeholder
    view_pattern = r"CREATE\s+(OR\s+REPLACE\s+)?VIEW\s+([\w.]+)\s+AS\s+(.+)"
    match = re.search(view_pattern, sql, re.IGNORECASE | re.DOTALL)

    if not match:
        raise ValueError("Invalid CREATE VIEW syntax")

    view_name = match.group(2)
    query = match.group(3).strip()

    # Create empty view placeholder
    df = DataFrame(pd.DataFrame({'note': ['View created']}))
    CatalogManager.register_table(view_name, df, table_type='VIEW')

    # Store view definition in metadata
    metadata = CatalogManager.get_table_metadata(view_name)
    metadata['view_text'] = query

    return DataFrame(pd.DataFrame({'Result': [f'View {view_name} created']}))


def _handle_create_temp_view(sql: str, spark_session):
    """
    CREATE [OR REPLACE] TEMP[ORARY] VIEW view_name AS select_statement
    """
    from .core import DataFrame

    view_pattern = r"CREATE\s+(OR\s+REPLACE\s+)?(TEMP|TEMPORARY)\s+VIEW\s+(\w+)\s+AS\s+(.+)"
    match = re.search(view_pattern, sql, re.IGNORECASE | re.DOTALL)

    if not match:
        raise ValueError("Invalid CREATE TEMP VIEW syntax")

    view_name = match.group(3)
    query = match.group(4).strip()

    # Create temporary view
    df = DataFrame(pd.DataFrame({'note': ['Temp view created']}))
    CatalogManager.create_temp_view(view_name, df, definition=query)

    return DataFrame(pd.DataFrame({'Result': [f'Temp view {view_name} created']}))


def _handle_alter_table(sql: str):
    """
    ALTER TABLE [catalog.][schema.]table SET TBLPROPERTIES (key='value', ...)
    ALTER TABLE [catalog.][schema.]table ALTER COLUMN col_name COMMENT 'text'
    """
    from .core import DataFrame

    # SET TBLPROPERTIES
    props_pattern = r"ALTER\s+TABLE\s+([\w.]+)\s+SET\s+TBLPROPERTIES\s*\((.*?)\)"
    props_match = re.search(props_pattern, sql, re.IGNORECASE)

    if props_match:
        table_name = props_match.group(1)
        props_str = props_match.group(2)

        # Parse properties
        metadata = CatalogManager.get_table_metadata(table_name)
        # Simple property parsing (key='value')
        for prop in props_str.split(','):
            prop = prop.strip()
            key_val = re.search(r"['\"]?(\w+)['\"]?\s*=\s*['\"]([^'\"]+)['\"]", prop)
            if key_val:
                key, value = key_val.group(1), key_val.group(2)
                metadata['properties'][key] = value

        return DataFrame(pd.DataFrame({'Result': [f'Table {table_name} altered']}))

    # ALTER COLUMN COMMENT
    comment_pattern = r"ALTER\s+TABLE\s+([\w.]+)\s+ALTER\s+COLUMN\s+(\w+)\s+COMMENT\s+'([^']+)'"
    comment_match = re.search(comment_pattern, sql, re.IGNORECASE)

    if comment_match:
        table_name = comment_match.group(1)
        col_name = comment_match.group(2)
        comment = comment_match.group(3)

        metadata = CatalogManager.get_table_metadata(table_name)
        for col in metadata['columns']:
            if col['name'] == col_name:
                col['comment'] = comment
                break

        return DataFrame(pd.DataFrame({'Result': [f'Column {col_name} comment updated']}))

    raise ValueError("Unsupported ALTER TABLE syntax")


# ============ DQL HANDLERS ============

def _handle_show_catalogs():
    """SHOW CATALOGS"""
    from .core import DataFrame

    catalogs = CatalogManager.get_catalogs()
    return DataFrame(pd.DataFrame({'catalog': catalogs}))


def _handle_show_schemas(sql: str):
    """SHOW SCHEMAS [IN catalog_name]"""
    from .core import DataFrame

    in_match = re.search(r"IN\s+(\w+)", sql, re.IGNORECASE)
    catalog = in_match.group(1) if in_match else current_catalog()

    schemas = CatalogManager.get_schemas(catalog)
    return DataFrame(pd.DataFrame({'databaseName': schemas}))


def _handle_show_tables(sql: str):
    """SHOW TABLES [IN [catalog.]schema]"""
    from .core import DataFrame

    in_match = re.search(r"IN\s+([\w.]+)", sql, re.IGNORECASE)
    schema_path = in_match.group(1) if in_match else None

    tables = CatalogManager.get_tables(schema_path)
    return DataFrame(pd.DataFrame({'tableName': tables}))


def _handle_describe_table(sql: str):
    """DESCRIBE [TABLE] [catalog.][schema.]table"""
    from .core import DataFrame

    # Pattern: DESCRIBE [TABLE] table_name
    pattern = r"DESC(?:RIBE)?(?:\s+TABLE)?\s+([\w.]+)"
    match = re.search(pattern, sql, re.IGNORECASE)

    if not match:
        raise ValueError("Invalid DESCRIBE syntax")

    table_name = match.group(1)
    metadata = CatalogManager.get_table_metadata(table_name)

    # Return column information
    columns_data = []
    for col in metadata['columns']:
        columns_data.append({
            'col_name': col['name'],
            'data_type': col['type'],
            'comment': col.get('comment', '')
        })

    return DataFrame(pd.DataFrame(columns_data))


def _handle_show_grants(sql: str):
    """SHOW GRANTS ON object_type object_name"""
    from .core import DataFrame

    # Pattern: SHOW GRANTS ON (TABLE|SCHEMA|CATALOG) name
    pattern = r"SHOW\s+GRANTS\s+ON\s+(\w+)\s+([\w.]+)"
    match = re.search(pattern, sql, re.IGNORECASE)

    if not match:
        raise ValueError("Invalid SHOW GRANTS syntax")

    object_type = match.group(1)
    object_name = match.group(2)

    grants = CatalogManager.show_grants(object_name)

    if not grants:
        return DataFrame(pd.DataFrame({'principal': [], 'action': []}))

    grants_data = []
    for grant in grants:
        grants_data.append({
            'principal': grant['principal'],
            'action': grant['privilege'],
            'objectType': grant['object_type']
        })

    return DataFrame(pd.DataFrame(grants_data))


# ============ ACL HANDLERS ============

def _handle_grant(sql: str):
    """GRANT privilege ON object_type object_name TO `principal`"""
    from .core import DataFrame

    # Pattern: GRANT (SELECT|MODIFY|ALL) ON (TABLE|SCHEMA|CATALOG) name TO `principal`
    pattern = r"GRANT\s+(SELECT|MODIFY|ALL|CREATE)\s+ON\s+(\w+)\s+([\w.]+)\s+TO\s+`([^`]+)`"
    match = re.search(pattern, sql, re.IGNORECASE)

    if not match:
        raise ValueError("Invalid GRANT syntax")

    privilege = match.group(1)
    object_type = match.group(2)
    object_name = match.group(3)
    principal = match.group(4)

    CatalogManager.grant_privilege(object_type, object_name, privilege, principal)

    return DataFrame(pd.DataFrame({'Result': [f'Granted {privilege} on {object_name} to {principal}']}))


def _handle_revoke(sql: str):
    """REVOKE privilege ON object_type object_name FROM `principal`"""
    from .core import DataFrame

    # Pattern: REVOKE (SELECT|MODIFY|ALL) ON (TABLE|SCHEMA|CATALOG) name FROM `principal`
    pattern = r"REVOKE\s+(SELECT|MODIFY|ALL|CREATE)\s+ON\s+(\w+)\s+([\w.]+)\s+FROM\s+`([^`]+)`"
    match = re.search(pattern, sql, re.IGNORECASE)

    if not match:
        raise ValueError("Invalid REVOKE syntax")

    privilege = match.group(1)
    object_type = match.group(2)
    object_name = match.group(3)
    principal = match.group(4)

    CatalogManager.revoke_privilege(object_type, object_name, privilege, principal)

    return DataFrame(pd.DataFrame({'Result': [f'Revoked {privilege} on {object_name} from {principal}']}))


# ============ CONTEXT HANDLERS ============

def _handle_use(sql: str):
    """USE [catalog.]schema"""
    from .core import DataFrame

    pattern = r"USE\s+([\w.]+)"
    match = re.search(pattern, sql, re.IGNORECASE)

    if not match:
        raise ValueError("Invalid USE syntax")

    schema_name = match.group(1)
    set_current_schema(schema_name)

    return DataFrame(pd.DataFrame({'Result': [f'Using {schema_name}']}))


# ============ INFORMATION SCHEMA HANDLER ============

def _handle_information_schema_query(sql: str, spark_session):
    """
    Handle SELECT queries from information_schema virtual tables.
    Supports: information_schema.tables, columns, schemata
    """
    from .core import DataFrame

    sql_lower = sql.lower()

    # Determine which information_schema table
    if 'information_schema.tables' in sql_lower:
        df = _get_information_schema_tables()
    elif 'information_schema.columns' in sql_lower:
        df = _get_information_schema_columns()
    elif 'information_schema.schemata' in sql_lower:
        df = _get_information_schema_schemata()
    else:
        raise ValueError("Unsupported information_schema table")

    # Apply WHERE clause if present (simple pandas query)
    where_match = re.search(r"WHERE\s+(.+?)(?:ORDER BY|LIMIT|$)", sql, re.IGNORECASE)
    if where_match:
        condition = where_match.group(1).strip()
        # Convert SQL to pandas query format
        condition = condition.replace('=', '==')
        try:
            df = df.query(condition)
        except:
            pass  # If query fails, return full result

    return DataFrame(df)


def _get_information_schema_tables():
    """Virtual table: information_schema.tables"""
    from .catalog import _CATALOG_REGISTRY

    rows = []
    for cat_name, cat_data in _CATALOG_REGISTRY.items():
        for schema_name, schema_data in cat_data['schemas'].items():
            for table_name, table_data in schema_data['tables'].items():
                rows.append({
                    'table_catalog': cat_name,
                    'table_schema': schema_name,
                    'table_name': table_name,
                    'table_type': table_data['type']
                })
    return pd.DataFrame(rows)


def _get_information_schema_columns():
    """Virtual table: information_schema.columns"""
    from .catalog import _CATALOG_REGISTRY

    rows = []
    for cat_name, cat_data in _CATALOG_REGISTRY.items():
        for schema_name, schema_data in cat_data['schemas'].items():
            for table_name, table_data in schema_data['tables'].items():
                for col in table_data['columns']:
                    rows.append({
                        'table_catalog': cat_name,
                        'table_schema': schema_name,
                        'table_name': table_name,
                        'column_name': col['name'],
                        'data_type': col['type'],
                        'ordinal_position': col.get('ordinal', 0)
                    })
    return pd.DataFrame(rows)


def _get_information_schema_schemata():
    """Virtual table: information_schema.schemata"""
    from .catalog import _CATALOG_REGISTRY

    rows = []
    for cat_name, cat_data in _CATALOG_REGISTRY.items():
        for schema_name, schema_data in cat_data['schemas'].items():
            rows.append({
                'catalog_name': cat_name,
                'schema_name': schema_name,
                'schema_owner': schema_data.get('owner', 'unknown')
            })
    return pd.DataFrame(rows)


# ============ REGISTER CATALOG FUNCTIONS ============
# Make catalog functions available in pyspark.sql
import sys
pyspark_sql = sys.modules.get('pyspark.sql')
if pyspark_sql:
    pyspark_sql.current_catalog = current_catalog
    pyspark_sql.current_database = current_database

print("âœ“ Unity Catalog shim loaded (complete bundle)")
