# PySpark Koans - Modular Next.js Architecture

Interactive, browser-based learning platform for PySpark and Delta Lake. Built with Next.js for scalability to 100+ koans.

## ğŸ—ï¸ Architecture Overview

### Key Design Decisions

- **Next.js** for file-based routing and automatic code splitting
- **One file per koan** for easy maintenance and scalability
- **Modular Python shims** separated by feature domain
- **Reusable React components** for consistent UX
- **Static export** for deployment anywhere

## ğŸ“ Project Structure

```
next-app/
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ index.js                    # Landing page / Dashboard
â”‚   â”œâ”€â”€ koans/
â”‚   â”‚   â””â”€â”€ [id].js                 # Individual koan page (dynamic route)
â”‚   â””â”€â”€ _app.js                     # App wrapper
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ koans/                      # Koan definitions
â”‚   â”‚   â”œâ”€â”€ pyspark/
â”‚   â”‚   â”‚   â”œâ”€â”€ basics/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ koan-001-create-dataframe.js
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ koan-002-select-columns.js
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚   â”œâ”€â”€ strings/
â”‚   â”‚   â”‚   â”œâ”€â”€ aggregations/
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ delta/
â”‚   â”‚   â”‚   â”œâ”€â”€ koan-101-create-table.js
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ index.js                # Koan registry
â”‚   â”‚
â”‚   â”œâ”€â”€ shims/                      # Python shim modules
â”‚   â”‚   â”œâ”€â”€ pyspark/
â”‚   â”‚   â”‚   â”œâ”€â”€ core.py            # Row, Column, DataFrame, SparkSession
â”‚   â”‚   â”‚   â”œâ”€â”€ functions.py       # SQL functions
â”‚   â”‚   â”‚   â”œâ”€â”€ window.py          # Window functions
â”‚   â”‚   â”‚   â””â”€â”€ io.py              # DataFrameReader/Writer
â”‚   â”‚   â”œâ”€â”€ delta/
â”‚   â”‚   â”‚   â”œâ”€â”€ core.py            # DeltaTable
â”‚   â”‚   â”‚   â””â”€â”€ storage.py         # In-memory Delta storage
â”‚   â”‚   â””â”€â”€ index.py               # Main shim entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ components/                 # React components
â”‚   â”‚   â”œâ”€â”€ KoanEditor.jsx         # Code editor
â”‚   â”‚   â”œâ”€â”€ OutputPanel.jsx        # Output display
â”‚   â”‚   â”œâ”€â”€ Sidebar.jsx            # Navigation
â”‚   â”‚   â”œâ”€â”€ KoanHeader.jsx         # Koan title/description
â”‚   â”‚   â”œâ”€â”€ HintPanel.jsx          # Hints
â”‚   â”‚   â””â”€â”€ Controls.jsx           # Action buttons
â”‚   â”‚
â”‚   â””â”€â”€ hooks/                      # Custom React hooks
â”‚       â”œâ”€â”€ usePyodide.js          # Pyodide initialization
â”‚       â”œâ”€â”€ useKoanProgress.js     # Progress tracking
â”‚       â””â”€â”€ useKoanExecution.js    # Code execution
â”‚
â”œâ”€â”€ public/
â”‚   â””â”€â”€ shims/                      # Compiled Python shims
â”‚       â”œâ”€â”€ pyspark-shim.py
â”‚       â””â”€â”€ delta-shim.py
â”‚
â”œâ”€â”€ package.json
â”œâ”€â”€ next.config.js                  # Next.js configuration
â””â”€â”€ tailwind.config.js              # Tailwind CSS config
```

## ğŸš€ Getting Started

### Installation

```bash
cd next-app
npm install
```

### Development

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000)

### Build for Production

```bash
npm run build     # Build Next.js app
npm run export    # Export as static site
```

Output will be in `out/` directory - deploy to any static host.

## ğŸ“ Adding New Koans

### 1. Create Koan File

```javascript
// src/koans/pyspark/strings/koan-013-case.js
export default {
  id: 13,
  title: "String Functions - Case",
  category: "String Functions",
  difficulty: "beginner",
  description: "Learn string case transformations",

  setup: `
data = [("alice",), ("BOB",)]
df = spark.createDataFrame(data, ["name"])
`,

  template: `# Convert to uppercase
result = df.withColumn("upper_name", ___(col("name")))

assert result.collect()[0]["upper_name"] == "ALICE"
print("âœ“ Converted to uppercase")
print("\\nğŸ‰ Koan complete!")`,

  solution: `result = df.withColumn("upper_name", upper(col("name")))`,

  hints: [
    "Use the upper() function",
    "Import it from pyspark.sql.functions"
  ],

  examCoverage: ["DEA", "DAA"],
  prerequisiteKoans: [1, 2],
  nextKoans: [14],
};
```

### 2. Register in Index

```javascript
// src/koans/index.js
import koan13 from './pyspark/strings/koan-013-case';

const koansById = {
  // ... existing koans
  13: koan13,
  // ... more koans
};
```

### 3. That's It!

Next.js automatically:
- Creates route `/koans/13`
- Pre-renders page at build time
- Code-splits the koan bundle

## ğŸ”§ Extending the Shim

### Adding a New PySpark Function

```python
# src/shims/pyspark/functions.py

def my_new_function(col_expr, param):
    """New function description"""
    if isinstance(col_expr, str):
        col_expr = col(col_expr)

    def transform(pdf):
        # Implement using pandas
        return pdf[col_expr.name].apply(lambda x: ...)

    new_col = Column(col_expr.name)
    new_col._transform_func = transform
    return new_col
```

### Adding Delta Lake Features

```python
# src/shims/delta/core.py

class DeltaTable:
    def my_new_operation(self, condition):
        """New Delta operation"""
        df = self._table_data.get_df()
        # Implement operation
        self._table_data._add_version(df, "MY_OPERATION")
```

## ğŸ“¦ Deployment

### GitHub Pages

```bash
# next.config.js
module.exports = {
  basePath: '/pyspark-koans',
  output: 'export',
};

# Deploy
npm run export
# Push out/ directory to gh-pages branch
```

### Netlify / Vercel

```bash
npm run export
# Point deployment to out/ directory
```

### Any Static Host

The `out/` directory contains pure static HTML/CSS/JS - deploy anywhere!

## ğŸ§ª Testing Strategy

### Component Testing

```bash
npm install --save-dev @testing-library/react jest
# Test components in isolation
```

### Koan Testing

```javascript
// Validate koan definitions
test('koan has required fields', () => {
  const koan = getKoan(1);
  expect(koan.id).toBeDefined();
  expect(koan.template).toContain('___');
  expect(koan.solution).toBeDefined();
});
```

## ğŸ¯ Roadmap to 100+ Koans

### Phase 1: Core PySpark (40 koans)
- âœ… Basics (7 koans)
- âœ… Column Operations (5 koans)
- âœ… String Functions (4 koans)
- âœ… Aggregations (3 koans)
- âœ… Joins (3 koans)
- âœ… Window Functions (3 koans)
- âœ… Null Handling (2 koans)
- âœ… Advanced (3 koans)
- âœ… Delta Lake (10 koans)

### Phase 2: Expanded PySpark (30 koans)
- Date/Time Functions (8 koans)
- Complex Types - Arrays & Maps (8 koans)
- UDFs & Custom Functions (6 koans)
- Performance Optimization (8 koans)

### Phase 3: Spark SQL (20 koans)
- Basic Queries (10 koans)
- Joins & CTEs (10 koans)

### Phase 4: MLflow & MLOps (14 koans)
- Experiment Tracking (8 koans)
- Model Registry (6 koans)

### Phase 5: DABs (8 koans)
- YAML Configuration (8 koans)

**Total: 112 koans** ğŸ‰

## ğŸ¤ Contributing

1. Add your koan file in appropriate category
2. Register in `src/koans/index.js`
3. Test locally with `npm run dev`
4. Submit PR

## ğŸ“„ License

MIT

## ğŸ™ Acknowledgments

- Pyodide team for Python in the browser
- Databricks for PySpark
- Ruby Koans for the learning methodology
